{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXRY8uXLJt61"
      },
      "outputs": [],
      "source": [
        "#import neccessary libraies\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "import string\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Volume\n",
        "def generate_large_dataset(): #function name\n",
        "  data = {\"id\"     : list(range(1, 1000001)),  #converts range from 1 to 1000000 to list\n",
        "          \"value\"  : np.random.randint(0,1000, 1000000) #np is for numeric operations, random no. from 0 to 999. and 100000 are total numbers\n",
        "          } #dictionary , key-value pairs\n",
        "  df = pd.DataFrame(data)  #DataFrame is a functions that creates table like format of data\n",
        "  #Two columns(id , value) and 1000000 rows\n",
        "  print(\"Large dataset processed: \", df.shape) #shape gives rows and column number"
      ],
      "metadata": {
        "id": "dbarFVYCJ5jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vareity\n",
        "def handle_vareity():  #function name\n",
        "  csv_data = pd.DataFrame({\"name\" : [\"Alice\", \"Bob\"],   \"age\" : [25, 30]})\n",
        "  #a dict with two key-val pairs, values are in form of lists\n",
        "  json_data = pd.DataFrame ({\"student\" : [{\"name\" : \"Alice\", \"age\" : 25}, {\"name\" : \"Bob\", \"age\" : 30}]})\n",
        "  # one dict with one key student whose val is a list that contain two elments that are both dicts and further these dicts have 2 2 key-val pairs\n",
        "  print(\"CSV Data: \\n\", csv_data)  #structured\n",
        "  print(\"JSON Data: \\n\", json_data)  #semi structured\n",
        "  #printing both formats"
      ],
      "metadata": {
        "id": "5hM15_iuKEcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Velocity\n",
        "def stream_data(): #function name\n",
        "  for _ in range(5):  # variable is not used so _ used. range= 0,1,2,3,4 (5 times)\n",
        "    print(\"streaming data\", \"\".join(random.choices(string.ascii_letters, k=10))) #\"\".join , it joins the elements of string like abcde\n",
        "    #random.choices , we can randomly selects multiple items, same item cannbe repeated\n",
        "    #string.ascii_letters has all upper, lowercase alphabets , we can have 10 letters like abMLOpytdJ\n",
        "    time.sleep(1)\n",
        "    #pause the program for 1 sec after 1 iteration"
      ],
      "metadata": {
        "id": "WnvCQX33LPz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Veracity\n",
        "def clean_data():  #function name\n",
        "  raw_data = {\"id\"    : [1, 2, None, 4],       #dict with 2 key-val\n",
        "              \"score\" : [90, \"N/A\", 85, 88]\n",
        "              }\n",
        "  df=pd.DataFrame(raw_data)  #DataFrame is a function that convert data into pandas dataframe\n",
        "  df.dropna(inplace=True)  #it removes any row that has none value\n",
        "  #access score column at left                 #to_numeric converts to numbers\n",
        "  df[\"score\"] = pd.to_numeric(df[\"score\"], errors = \"coerce\")  # coerce means that can not converted is converted into NaN\n",
        "  print(\"Cleaned Data: \\n\", df)"
      ],
      "metadata": {
        "id": "2_J-gDBZlqQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "characteristic = random.choice([\"Volume\", \"Vareity\", \"Velocity\", \"Veracity\"])\n",
        "print(f\"selected characteristic: {characteristic}\")\n",
        "if characteristic == \"Volume\":\n",
        "  generate_large_dataset()\n",
        "elif characteristic == \"Vareity\":\n",
        "  handle_vareity()\n",
        "elif characteristic == \"Velocity\":\n",
        "  stream_data()\n",
        "elif characteristic == \"Veracity\":\n",
        "  clean_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRO2AzTIxIoH",
        "outputId": "862ef9d3-e0e5-485f-fcd4-3435197b8131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "selected characteristic: Vareity\n",
            "CSV Data: \n",
            "     name  age\n",
            "0  Alice   25\n",
            "1    Bob   30\n",
            "JSON Data: \n",
            "                         student\n",
            "0  {'name': 'Alice', 'age': 25}\n",
            "1    {'name': 'Bob', 'age': 30}\n"
          ]
        }
      ]
    }
  ]
}